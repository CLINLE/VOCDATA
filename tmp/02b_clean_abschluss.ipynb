{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b8d6259",
   "metadata": {},
   "source": [
    "# 02b · Cleaning – Abschlussquoten\n",
    "\n",
    "**Zweck**  \n",
    "Analog zu 02a, aber für Sek II-Abschlussquoten.\n",
    "\n",
    "**Wichtigste Schritte**  \n",
    "1. Sheets laden & numerische Spalten casten  \n",
    "2. Kontext-Spalten (`aggregation_level`, …) ergänzen  \n",
    "3. Dubletten entfernen (Dimensions-Key + Aggregationslevel)  \n",
    "4. Export: `tmp/abs_clean.parquet`\n",
    "\n",
    "**Ergebnis**  \n",
    "`tmp/abs_clean.parquet`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc6433d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-30T11:49:34.675221Z",
     "iopub.status.busy": "2025-06-30T11:49:34.674337Z",
     "iopub.status.idle": "2025-06-30T11:49:35.145436Z",
     "shell.execute_reply": "2025-06-30T11:49:35.144899Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quelle: ..\\..\\data\\bfs_data_abschlussquote.xlsx\n"
     ]
    }
   ],
   "source": [
    "#Imports & Konstanten\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "DATA_DIR = Path(\"../../data\")\n",
    "TMP_DIR  = Path(\"../../tmp\")\n",
    "SRC_ABS  = DATA_DIR / \"bfs_data_abschlussquote.xlsx\"\n",
    "TMP_FILE = TMP_DIR  / \"abs_clean.parquet\"\n",
    "\n",
    "TMP_DIR.mkdir(exist_ok=True, parents=True)\n",
    "print(\"Quelle:\", SRC_ABS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b4b0df0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-30T11:49:35.146968Z",
     "iopub.status.busy": "2025-06-30T11:49:35.146968Z",
     "iopub.status.idle": "2025-06-30T11:49:35.150374Z",
     "shell.execute_reply": "2025-06-30T11:49:35.150374Z"
    }
   },
   "outputs": [],
   "source": [
    "#Hilfsfunktionen\n",
    "def header_row(xls, sh):\n",
    "    top = pd.read_excel(xls, sheet_name=sh, nrows=15, header=None)\n",
    "    return next(i for i,r in top.iterrows() if r.notna().sum() >= 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25e0ce2e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-30T11:49:35.154374Z",
     "iopub.status.busy": "2025-06-30T11:49:35.153443Z",
     "iopub.status.idle": "2025-06-30T11:49:35.385646Z",
     "shell.execute_reply": "2025-06-30T11:49:35.384392Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ T1_SekII_1st_25_Merkm_Data: 13 Zeilen\n",
      "✓ T2_SekII_1st_25_Kant_Data: 27 Zeilen\n",
      "✓ T3_Matura_Merkm_Data: 13 Zeilen\n",
      "✓ T4_Matura_Kant_Data: 27 Zeilen\n"
     ]
    }
   ],
   "source": [
    "#Einlesen & Bereinigen\n",
    "xls = pd.ExcelFile(SRC_ABS)\n",
    "DATA_SHEETS = [s for s in xls.sheet_names if s.endswith(\"_Data\")]\n",
    "\n",
    "rows = []\n",
    "for sh in DATA_SHEETS:\n",
    "    agg = sh.split(\"_\")[0]          # z. B. 'T1'\n",
    "    hdr = header_row(xls, sh)\n",
    "    df  = pd.read_excel(xls, sheet_name=sh, header=hdr)\n",
    "\n",
    "    # numerische Spalten: alles, was int/float sein sollte\n",
    "    num_like = [c for c in df.columns if\n",
    "                any(tag in c.lower() for tag in [\"anz\", \"%\", \"rate\", \"cnt\"])]\n",
    "    for c in num_like:\n",
    "        df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "    # Standardisierung: Strings trimmen + upper\n",
    "    str_cols = df.select_dtypes(include=\"object\").columns\n",
    "    df[str_cols] = df[str_cols].apply(lambda s: s.str.strip())\n",
    "\n",
    "    df[\"aggregation_level\"] = agg\n",
    "    rows.append(df)\n",
    "\n",
    "    print(f\"✓ {sh}: {len(df)} Zeilen\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b803321a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-30T11:49:35.388661Z",
     "iopub.status.busy": "2025-06-30T11:49:35.388661Z",
     "iopub.status.idle": "2025-06-30T11:49:35.415608Z",
     "shell.execute_reply": "2025-06-30T11:49:35.415608Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates: 80 → 80\n",
      "Parquet geschrieben: ..\\..\\tmp\\abs_clean.parquet | Zeilen: 80\n"
     ]
    }
   ],
   "source": [
    "#Dubletten entfernen & Export\n",
    "df_all = pd.concat(rows, ignore_index=True)\n",
    "\n",
    "key_cols = [\"aggregation_level\",        # aus Sheet\n",
    "            \"merkmal\", \"kategorie\",     # BFS-Hierarchie\n",
    "            \"jahr\"] + [c for c in df_all.columns if c.endswith(\"_code\")]\n",
    "before, after = len(df_all), len(df_all.drop_duplicates(subset=key_cols))\n",
    "df_all = df_all.drop_duplicates(subset=key_cols)\n",
    "\n",
    "print(f\"Duplicates: {before} → {after}\")\n",
    "\n",
    "df_all.to_parquet(TMP_FILE, index=False)\n",
    "print(\"Parquet geschrieben:\", TMP_FILE, \"| Zeilen:\", len(df_all))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vocdata",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
