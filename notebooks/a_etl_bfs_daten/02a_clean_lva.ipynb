{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "704f9198",
   "metadata": {},
   "source": [
    "# 02a · Cleaning – Lehrvertragsauflösungen\n",
    "\n",
    "**Zweck**  \n",
    "Rohdaten in ein einheitliches, analysierbares Format bringen.\n",
    "\n",
    "**Wichtigste Schritte**  \n",
    "1. Alle *_Data-Sheets laden, fehlende Spalten harmonisieren  \n",
    "2. Flags bauen  \n",
    "   - `is_lva` ↔ mind. eine LVA-Zahl oder Suppression-Marker  \n",
    "   - `is_wiedereinstieg` ↔ Wiedereinstiegs-Spalte nicht NA  \n",
    "3. Kontextspalten ergänzen (`aggregation_level`, `kohorte_id`)  \n",
    "4. Dubletten­killer auf definierter Key-Kombi  \n",
    "5. Export: `tmp/lva_clean.parquet`\n",
    "\n",
    "**Ergebnis**  \n",
    "`tmp/lva_clean.parquet` – bereinigter, harmonisierter Datensatz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e39c879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quelle: ..\\..\\data\\bfs_data_lva.xlsx\n",
      "✓ T1_Lernform_Data: 6 Zeilen\n",
      "✓ T2_Geschlecht_Data: 9 Zeilen\n",
      "✓ T3_MIG_Status_Data: 12 Zeilen\n",
      "✓ T4.1.1_ISCED_Beruf_EBA_Data: 55 Zeilen\n",
      "✓ T4.2.1_ISCED_Beruf_EFZ3_Data: 106 Zeilen\n",
      "✓ T4.3.1_ISCED_Beruf_EFZ4_Data: 67 Zeilen\n",
      "✓ T5_LVA_t_Data: 12 Zeilen\n",
      "✓ T6_Wiedereinstieg_Data: 6 Zeilen\n",
      "✓ T7_Zeitpkt_Wiedereinstieg_Data: 9 Zeilen\n",
      "✓ T8_Geschlecht_Wiedereinst_Data: 6 Zeilen\n",
      "✓ T9_ISCED_Beruf_WEstg_G_Data: 207 Zeilen\n",
      "✓ T9_ISCED_Beruf_WEstg_EBA_Data: 48 Zeilen\n",
      "✓ T9_ISCED_Beruf_WEstg_EFZ3_Data: 98 Zeilen\n",
      "✓ T9_ISCED_Beruf_WEstg_EFZ4_Data: 61 Zeilen\n",
      "✓ T10_Anschlussart_LVA_Data: 24 Zeilen\n",
      "✓ T11_QV_Status_Ende_t_Data: 12 Zeilen\n",
      "✓ T12_QV_Status_Ende_t_sex_Data: 24 Zeilen\n",
      "✓ T13_QV_Status_Ende_t_MIG_Data: 48 Zeilen\n",
      "✓ T14_QV_Status_Ende_t_Beruf_Data: 280 Zeilen\n",
      "Dubletten entfernt: 1090 → 1081\n",
      "Parquet geschrieben: ..\\..\\tmp\\lva_clean.parquet | Zeilen: 1081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\claud\\AppData\\Local\\Temp\\ipykernel_29264\\2058143933.py:94: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_all = pd.concat(all_frames, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# %%\n",
    "# 02a_clean_lva.ipynb  –  Cleaning & Parquet\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from IPython.display import display\n",
    "\n",
    "DATA_DIR  = Path(\"../../data\")\n",
    "TMP_DIR   = Path(\"../../tmp\")\n",
    "SRC_LVA   = DATA_DIR / \"bfs_data_lva.xlsx\"\n",
    "TMP_FILE  = TMP_DIR  / \"lva_clean.parquet\"\n",
    "TMP_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "NUM_COLS  = [\"anzahl_lernende\", \"anzahl_lehrvertraege_lva\",\n",
    "             \"anzahl_lernende_lva\", \"anzahl_lernende_wiedereinstieg\"]\n",
    "\n",
    "KEEP_COLS = [\n",
    "    \"aggregation_level\", \"kohorte_id\",\n",
    "    \"abschlussniveau\", \"lernform\", \"geschlecht\", \"mig_status\",\n",
    "    \"lva_anschlussart\", \"qv_status\", \"lva_zeitpunkt\", \"wiedereinst_dauer\",\n",
    "    \"ausbildungsfeld_isced_code\", \"ausbildungsfeld_isced_bez\", \"beruf_bez\",\n",
    "    *NUM_COLS,                      # ← fügt alle vier numerischen Felder ein\n",
    "    \"is_lva\", \"is_wiedereinstieg\", \"datenstatus\"\n",
    "]\n",
    "\n",
    "def header_row(xls, sh):\n",
    "    top = pd.read_excel(xls, sheet_name=sh, nrows=15, header=None)\n",
    "    return next(i for i, r in top.iterrows() if r.notna().sum() >= 3)\n",
    "\n",
    "print(\"Quelle:\", SRC_LVA)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1) Alle *_Data-Sheets durchgehen (einlesen)\n",
    "# ------------------------------------------------------------\n",
    "xls       = pd.ExcelFile(SRC_LVA)\n",
    "DATA_SHEETS = [s for s in xls.sheet_names if s.endswith(\"_Data\")]\n",
    "all_frames  = []                         # statt rows-Liste\n",
    "\n",
    "\n",
    "\n",
    "for sh in DATA_SHEETS:\n",
    "    agg = sh.split(\"_\")[0]                 # z. B. \"T1\"\n",
    "    hdr = header_row(xls, sh)\n",
    "    df  = pd.read_excel(xls, sheet_name=sh, header=hdr)\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # 1) fehlende numerische Spalten ergänzen\n",
    "    # --------------------------------------------------\n",
    "\n",
    "    for col in NUM_COLS:\n",
    "        if col not in df.columns:\n",
    "            df[col] = pd.NA\n",
    "\n",
    "    # 2) fehlende kategoriale Spalte ergänzen\n",
    "    if \"datenstatus\" not in df.columns:\n",
    "        df[\"datenstatus\"] = pd.NA\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # 3) Flags bauen & berechnen  (robust) - Sobald in irgendeiner der vier Spalten,inkl. datenstatus (etwa „<20“, „<30“) ein Wert steht, is_lva = 1.\n",
    "    # --------------------------------------------------\n",
    "    flag_cols = [\n",
    "        \"anzahl_lernende_lva\",\n",
    "        \"anzahl_lehrvertraege_lva\",\n",
    "        \"anzahl_lernende_wiedereinstieg\",\n",
    "        \"datenstatus\",\n",
    "    ]\n",
    "    df[\"is_lva\"] = (\n",
    "        df[df.columns.intersection(flag_cols)]\n",
    "        .notna()\n",
    "        .any(axis=1)\n",
    "        .astype(int)\n",
    "    )\n",
    "    \n",
    "    df[\"is_wiedereinstieg\"] = (\n",
    "        df[\"anzahl_lernende_wiedereinstieg\"].notna() |\n",
    "        df[\"datenstatus\"].astype(str).str.startswith(\"<\")\n",
    "    ).astype(int)\n",
    "\n",
    "\n",
    "    # 4) Kontextspalten ergänzen\n",
    "    df[\"aggregation_level\"] = agg\n",
    "    df[\"kohorte_id\"]        = 1\n",
    "\n",
    "   # 5) genau die Zielspalten – fehlende werden automatisch angelegt\n",
    "    df = df.reindex(columns=KEEP_COLS, fill_value=pd.NA)\n",
    "\n",
    "    # 6) ans Gesamtergebnis anhängen\n",
    "    all_frames.append(df)\n",
    "    print(f\"✓ {sh}: {len(df)} Zeilen\")\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 6) Gesamt-DataFrame, Dubletten killen\n",
    "# ------------------------------------------------------------\n",
    "df_all = pd.concat(all_frames, ignore_index=True)\n",
    "before = len(df_all)\n",
    "df_all = df_all.drop_duplicates(subset=[\n",
    "    \"aggregation_level\",\"kohorte_id\",\n",
    "    \"abschlussniveau\",\"lernform\",\"geschlecht\",\"mig_status\",\n",
    "    \"lva_anschlussart\",\"qv_status\",\"lva_zeitpunkt\",\"wiedereinst_dauer\",\n",
    "    \"ausbildungsfeld_isced_code\",\"beruf_bez\"\n",
    "])\n",
    "print(f\"Dubletten entfernt: {before} → {len(df_all)}\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 7) Parquet schreiben\n",
    "# ------------------------------------------------------------\n",
    "df_all.to_parquet(TMP_FILE, index=False)\n",
    "print(\"Parquet geschrieben:\", TMP_FILE, \"| Zeilen:\", len(df_all))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vocdata",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
