{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4899b56",
   "metadata": {},
   "source": [
    "# 04b · Load – fact_abschluss_stats\n",
    "\n",
    "**Zweck**  \n",
    "Lädt die bereinigten Abschlussquoten-Fakten. in die Data-Warehouse-Faktentabelle. \n",
    "**Wichtigste Schritte**  \n",
    "1. `tmp/abs_clean.parquet` lesen  \n",
    "2. FK-Mapping für Geo- und Demografie-Dimensionen  \n",
    "3. Spalte `aggregation_level` ggf. nachrüsten  \n",
    "4. `TRUNCATE fact_abschluss_stats` → Bulk-Insert\n",
    "\n",
    "**Ergebnis**  \n",
    "Tablle `fact_abschluss_stats` neu erstellt/gefüllt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2c9495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spalte aggregation_level existiert bereits – OK.\n",
      "Geladene Zeilen: 80\n",
      "Nach Mapping: 80 Zeilen\n",
      "✔ fact_abschluss_stats neu geladen: 80 Zeilen\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# ───────────────────────── Imports & Konstanten ─────────────────────────\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "TMP_FILE = Path(\"../../tmp/abs_clean.parquet\")          # ggf. anpassen\n",
    "ENGINE   = create_engine(\n",
    "    \"mysql+pymysql://root:voc_root@localhost:3306/vocdata\",\n",
    "    future=True, echo=False)\n",
    "\n",
    "# ───── 0) Spalte aggregation_level sicherstellen ───────────────────────\n",
    "with ENGINE.begin() as con:\n",
    "    exists = con.scalar(text(\"\"\"\n",
    "        SELECT COUNT(*) FROM information_schema.COLUMNS\n",
    "        WHERE table_schema = DATABASE()\n",
    "          AND table_name   = 'fact_abschluss_stats'\n",
    "          AND column_name  = 'aggregation_level'\n",
    "    \"\"\"))\n",
    "    if exists == 0:\n",
    "        con.exec_driver_sql(\"\"\"\n",
    "            ALTER TABLE fact_abschluss_stats\n",
    "            ADD COLUMN aggregation_level VARCHAR(12) NOT NULL DEFAULT ''\n",
    "        \"\"\")\n",
    "        print(\"Spalte aggregation_level wurde angelegt.\")\n",
    "    else:\n",
    "        print(\"Spalte aggregation_level existiert bereits – OK.\")\n",
    "\n",
    "# ───── 1) Parquet lesen ────────────────────────────────────────────────\n",
    "df = pd.read_parquet(TMP_FILE)\n",
    "print(\"Geladene Zeilen:\", len(df))\n",
    "\n",
    "# ───── 2) FK-Lookups aufbauen ──────────────────────────────────────────\n",
    "DIM_TABLES = [\"gemeindetyp\", \"sprachregion\", \"kanton\",\n",
    "              \"geschlecht\", \"mig_status\"]\n",
    "\n",
    "lookups = {}\n",
    "with ENGINE.begin() as con:\n",
    "    for dim in DIM_TABLES:\n",
    "        d = pd.read_sql(f\"SELECT * FROM dim_{dim}\", con)\n",
    "        lookups[dim] = d.set_index(f\"{dim}_code\")[f\"{dim}_id\"].to_dict()\n",
    "\n",
    "def fk(dim: str, val) -> int:\n",
    "    if val is None or str(val).strip() == \"\":\n",
    "        return 0                          # UNKNOWN\n",
    "    return lookups[dim].get(str(val).strip().upper(), 0)\n",
    "\n",
    "# ───── 3) Mapping anwenden ─────────────────────────────────────────────\n",
    "mapped = []\n",
    "for _, r in df.iterrows():\n",
    "    mapped.append({\n",
    "        \"aggregation_level\":  r[\"aggregation_level\"],          # aus Sheet-Präfix\n",
    "        \"gemeindetyp_id\":     fk(\"gemeindetyp\",  r.get(\"gemeindetyp_code\")),\n",
    "        \"sprachregion_id\":    fk(\"sprachregion\", r.get(\"sprachregion_code\")),\n",
    "        \"kanton_id\":          fk(\"kanton\",       r.get(\"kanton_code\")),\n",
    "        \"geschlecht_id\":      fk(\"geschlecht\",   r.get(\"geschlecht_code\")),\n",
    "        \"mig_status_id\":      fk(\"mig_status\",   r.get(\"mig_status_code\")),\n",
    "        \"cnt_tot_25j\":            r[\"total_anz_25J\"],\n",
    "        \"cnt_abschluesse\":        r[\"total_anz_sekII_erstabschluss_25J\"],\n",
    "        \"cnt_abschluss_lehre\":    r[\"Lehre_anz_sekII_erstabschluss_25J\"],\n",
    "        \"cnt_abschluss_allg\":     r[\"allg_bildg_anz_sekII_erstabschluss_25J\"],\n",
    "        \"rate_abschluss_tot\":     r[\"total_%_sekII_erstabschluss_25J\"],\n",
    "        \"rate_abschluss_lehre\":   r[\"Lehre_%_sekII_erstabschluss_25J\"],\n",
    "        \"rate_abschluss_allg\":    r[\"allg_bildg_%_sekII_erstabschluss_25J\"]\n",
    "    })\n",
    "\n",
    "fact_df = pd.DataFrame(mapped)\n",
    "print(\"Nach Mapping:\", len(fact_df), \"Zeilen\")\n",
    "\n",
    "# ───── 4) Tabelle leeren & Insert ──────────────────────────────────────\n",
    "with ENGINE.begin() as con:\n",
    "    con.exec_driver_sql(\"TRUNCATE TABLE fact_abschluss_stats;\")\n",
    "    fact_df.to_sql(\"fact_abschluss_stats\", con,\n",
    "                   if_exists=\"append\", index=False, method=\"multi\")\n",
    "\n",
    "print(\"✔ fact_abschluss_stats neu geladen:\", len(fact_df), \"Zeilen\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vocdata",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
