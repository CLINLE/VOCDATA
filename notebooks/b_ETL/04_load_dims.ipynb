{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "126da82b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> lade dim_abschlussniveau\n",
      "✔ dim_abschlussniveau geladen: 4 Einträge\n",
      ">>> lade dim_lernform\n",
      "✔ dim_lernform geladen: 2 Einträge\n",
      ">>> lade dim_geschlecht\n",
      "✔ dim_geschlecht geladen: 3 Einträge\n",
      ">>> lade dim_mig_status\n",
      "✔ dim_mig_status geladen: 5 Einträge\n",
      ">>> lade dim_lva_anschlussart\n",
      "✔ dim_lva_anschlussart geladen: 8 Einträge\n",
      ">>> lade dim_qv_status\n",
      "✔ dim_qv_status geladen: 4 Einträge\n",
      ">>> lade dim_lva_zeitpunkt\n",
      "✔ dim_lva_zeitpunkt geladen: 4 Einträge\n",
      ">>> lade dim_wiedereinst_dauer\n",
      "✔ dim_wiedereinst_dauer geladen: 3 Einträge\n",
      ">>> lade dim_isced\n",
      "✔ dim_isced geladen: 32 Einträge\n",
      ">>> lade dim_beruf_bez\n",
      "✔ dim_beruf_bez geladen: 228 Einträge\n",
      ">>> lade dim_jahr\n",
      "✔ dim_jahr geladen: 1 Einträge\n",
      ">>> lade dim_merkmal\n",
      "✔ dim_merkmal geladen: 6 Einträge\n",
      ">>> lade dim_kategorie\n",
      "✔ dim_kategorie geladen: 39 Einträge\n"
     ]
    }
   ],
   "source": [
    "# %% ─────────  SETUP  ─────────\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "from pathlib import Path\n",
    "\n",
    "SRC_FILES = [\n",
    "    Path(\"../../data/bfs_data_lva.xlsx\"),\n",
    "    Path(\"../../data/bfs_data_abschlussquote.xlsx\")   # ← neu\n",
    "] \n",
    "engine   = create_engine(\"mysql+pymysql://root:voc_root@localhost:3306/vocdata\", echo=False)\n",
    "for src in SRC_FILES:\n",
    "    xls = pd.ExcelFile(src)\n",
    "\n",
    "DIM_MAP = {\n",
    "    \"abschlussniveau\":   [\"abschlussniveau\"],\n",
    "    \"lernform\":          [\"lernform\"],\n",
    "    \"geschlecht\":        [\"geschlecht\"],\n",
    "    \"mig_status\":        [\"mig_status\"],\n",
    "    \"lva_anschlussart\":  [\"lva_anschlussart\"],\n",
    "    \"qv_status\":         [\"qv_status\"],\n",
    "    \"lva_zeitpunkt\":      [\"lva_zeitpunkt\"],\n",
    "    \"wiedereinst_dauer\": [\"wiedereinstieg_dauer\"],\n",
    "    \"isced\":             [\"ausbildungsfeld_isced_code\", \"ausbildungsfeld_isced_bez\"],\n",
    "    \"beruf_bez\":         [\"beruf_bez\"],\n",
    "    \"jahr\":              [\"jahr\"],           # INT – wird als Code & Bez gleich genutzt\n",
    "    \"merkmal\":            [\"merkmal\"],\n",
    "    \"kategorie\":         [\"kategorie\"],\n",
    "}\n",
    "\n",
    "# %% ─────────  HELPER  ─────────\n",
    "def collect_values(df, cols):\n",
    "    \"\"\"Extrahiert Code/Bez-Paare oder Einzel-Bezeichnungen aus einem Sheet.\"\"\"\n",
    "    if len(cols) == 2:                             # Code + Bez\n",
    "        code, bez = cols\n",
    "        if {code, bez}.issubset(df.columns):\n",
    "            return (\n",
    "                df[[code, bez]].dropna()\n",
    "                  .astype(str).apply(lambda s: s.str.strip())\n",
    "                  .drop_duplicates()\n",
    "                  .itertuples(index=False, name=None)\n",
    "            )\n",
    "    else:                                          # nur Bez\n",
    "        col = cols[0]\n",
    "        if col in df.columns:\n",
    "            return df[col].dropna().astype(str).str.strip().unique()\n",
    "    return []\n",
    "\n",
    "def create_dim(con, dim, df):\n",
    "    table = f\"dim_{dim}\"\n",
    "\n",
    "    # 1) Tabelle mit korrektem Schema sicherstellen  (nur 1× pro Dim nötig)\n",
    "    if df.shape[1] == 3:                                    # id + code + bez\n",
    "        con.execute(text(f\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS {table} (\n",
    "                {dim}_id   INT UNSIGNED PRIMARY KEY,\n",
    "                {dim}_code VARCHAR(100) UNIQUE,\n",
    "                {dim}_bez  VARCHAR(200)\n",
    "            ) ENGINE=InnoDB;\n",
    "        \"\"\"))\n",
    "    else:                                                   # id + bez (+ code abgeleitet)\n",
    "        con.execute(text(f\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS {table} (\n",
    "                {dim}_id   INT UNSIGNED PRIMARY KEY,\n",
    "                {dim}_bez  VARCHAR(200) UNIQUE,\n",
    "                {dim}_code VARCHAR(100)\n",
    "            ) ENGINE=InnoDB;\n",
    "        \"\"\"))\n",
    "\n",
    "    # 2) Inhalt leeren (FK-sicher, weil Parent-Tabelle) und neu füllen\n",
    "    con.execute(text(\"SET foreign_key_checks = 0;\"))\n",
    "    con.execute(text(f\"TRUNCATE TABLE {table};\"))\n",
    "    con.execute(text(\"SET foreign_key_checks = 1;\"))\n",
    "\n",
    "    df = df.drop_duplicates(subset=df.columns[1:])          # Duplikate raus\n",
    "    df.to_sql(table, con, if_exists=\"append\", index=False, method=\"multi\")\n",
    "    print(f\"✔ {table} geladen:\", len(df), \"Einträge\")\n",
    "\n",
    "# %% ─────────  LOAD DIMENSIONS  ─────────\n",
    "with engine.begin() as con:\n",
    "    for dim, cols in DIM_MAP.items():\n",
    "        print(f\">>> lade dim_{dim}\")\n",
    "        values = set()\n",
    "\n",
    "        # --- ALLE Excel-Quellen durchgehen ---\n",
    "        for src in SRC_FILES:\n",
    "            xls = pd.ExcelFile(src)\n",
    "            for sh in xls.sheet_names:\n",
    "                if sh.endswith(\"_Data\"):\n",
    "                    df_sheet = pd.read_excel(\n",
    "                        xls, sheet_name=sh,\n",
    "                        usecols=lambda c: c.strip() in cols\n",
    "                    )\n",
    "                    values.update(collect_values(df_sheet, cols))\n",
    "\n",
    "        # DataFrame bilden\n",
    "        if len(cols) == 2:                             # Code + Bez\n",
    "            dim_df = (\n",
    "                pd.DataFrame(sorted(values), columns=[f\"{dim}_code\", f\"{dim}_bez\"])\n",
    "                  .reset_index(names=f\"{dim}_id\")\n",
    "                  .assign(**{f\"{dim}_id\": lambda d: d[f\"{dim}_id\"] + 1})\n",
    "            )\n",
    "        else:                                          # nur Bez\n",
    "            dim_df = (\n",
    "                pd.DataFrame(sorted(values), columns=[f\"{dim}_bez\"])\n",
    "                  .assign(**{f\"{dim}_code\": lambda d: d[f\"{dim}_bez\"].str.upper()})\n",
    "                  .reset_index(names=f\"{dim}_id\")\n",
    "                  .assign(**{f\"{dim}_id\": lambda d: d[f\"{dim}_id\"] + 1})\n",
    "            )\n",
    "\n",
    "        create_dim(con, dim, dim_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vocdata",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
