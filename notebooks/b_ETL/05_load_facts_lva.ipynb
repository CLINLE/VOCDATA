{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abd633e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fact_lva_stats geleert – Import startet …\n",
      "✓ T1_Lernform_Data: 7 Zeilen gelesen\n",
      "✓ T2_Geschlecht_Data: 9 Zeilen gelesen\n",
      "✓ T3_MIG_Status_Data: 13 Zeilen gelesen\n",
      "✓ T4_ISCED_Data: 31 Zeilen gelesen\n",
      "✓ T4.1_ISCED_EBA_Data: 20 Zeilen gelesen\n",
      "✓ T4.2_ISCED_EFZ3_Data: 30 Zeilen gelesen\n",
      "✓ T4.3_ISCED_EFZ4_Data: 18 Zeilen gelesen\n",
      "✓ T4.1.1_ISCED_Beruf_EBA_Data: 55 Zeilen gelesen\n",
      "✓ T4.2.1_ISCED_Beruf_EFZ3_Data: 106 Zeilen gelesen\n",
      "✓ T4.3.1_ISCED_Beruf_EFZ4_Data: 67 Zeilen gelesen\n",
      "✓ T5_LVA_t_Data: 12 Zeilen gelesen\n",
      "✓ T6_Wiedereinstieg_Data: 6 Zeilen gelesen\n",
      "✓ T7_Zeitpkt_Wiedereinstieg_Data: 9 Zeilen gelesen\n",
      "✓ T8_Geschlecht_Wiedereinst_Data: 6 Zeilen gelesen\n",
      "✓ T9_ISCED_Beruf_WEstg_G_Data: 207 Zeilen gelesen\n",
      "✓ T9_ISCED_Beruf_WEstg_EBA_Data: 48 Zeilen gelesen\n",
      "✓ T9_ISCED_Beruf_WEstg_EFZ3_Data: 98 Zeilen gelesen\n",
      "✓ T9_ISCED_Beruf_WEstg_EFZ4_Data: 61 Zeilen gelesen\n",
      "✓ T10_Anschlussart_LVA_Data: 24 Zeilen gelesen\n",
      "✓ T11_QV_Status_Ende_t_Data: 12 Zeilen gelesen\n",
      "✓ T12_QV_Status_Ende_t_sex_Data: 24 Zeilen gelesen\n",
      "✓ T13_QV_Status_Ende_t_MIG_Data: 48 Zeilen gelesen\n",
      "✓ T14_QV_Status_Ende_t_Beruf_Data: 280 Zeilen gelesen\n",
      "✔ fact_lva_stats geladen: 1191 Zeilen\n"
     ]
    }
   ],
   "source": [
    "# ----------------- 05_load_facts_lva — Komplett-Loader -----------------\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy import text        \n",
    "\n",
    "\n",
    "# ── 1. Pfad & DB ───────────────────────────────────────────────────────\n",
    "SRC_FILE = Path(\"../../data/bfs_data_lva.xlsx\")          # relativ zum Repo\n",
    "engine    = create_engine(\"mysql+pymysql://root:voc_root@localhost:3306/vocdata\",\n",
    "                          future=True, echo=False)\n",
    "\n",
    "# ── 2. Dimension-Lookups holen  (Key = Code/Bez  ➜  Value = ID) ────────\n",
    "dim_tables = [\n",
    "    \"abschlussniveau\", \"lernform\", \"geschlecht\", \"mig_status\",\n",
    "    \"lva_anschlussart\", \"qv_status\", \"lva_zeitpunkt\",\n",
    "    \"wiedereinst_dauer\", \"isced\", \"beruf\"\n",
    "]\n",
    "\n",
    "lookups = {}\n",
    "with engine.begin() as con:\n",
    "    for dim in dim_tables:\n",
    "        df = pd.read_sql(f\"SELECT * FROM dim_{dim}\", con)\n",
    "        key = f\"{dim}_code\" if f\"{dim}_code\" in df.columns else f\"{dim}_bez\"\n",
    "        lookups[dim] = df.set_index(key)[f\"{dim}_id\"].to_dict()\n",
    "\n",
    "def fk(dim, val):\n",
    "    \"\"\"Liefert gültige FK-ID oder 0 (UNKNOWN).\"\"\"\n",
    "    return 0 if pd.isna(val) or str(val).strip()==\"\" \\\n",
    "             else lookups[dim].get(str(val).strip().upper(), 0)\n",
    "\n",
    "# ── 3. Faktentabelle leeren ────────────────────────────────────────────\n",
    "with engine.begin() as con:\n",
    "    con.exec_driver_sql(\"TRUNCATE TABLE fact_lva_stats;\")\n",
    "print(\"fact_lva_stats geleert – Import startet …\")\n",
    "\n",
    "# ── 4. Excel durchgehen & Zeilen sammeln ───────────────────────────────\n",
    "rows, xls = [], pd.ExcelFile(SRC_FILE)\n",
    "for sh in [s for s in xls.sheet_names if s.endswith(\"_Data\")]:\n",
    "    # Header suchen (erste Zeile mit ≥3 Werten)\n",
    "    header = next(i for i,r in pd.read_excel(xls, sheet_name=sh,\n",
    "                                             nrows=15, header=None\n",
    "                                             ).iterrows() if r.notna().sum()>=3)\n",
    "    df = pd.read_excel(xls, sheet_name=sh, header=header)\n",
    "\n",
    "    # numerische Spalten sicher konvertieren\n",
    "    for col in [\"anzahl_lernende_lva\",\"anzahl_lernende_wiedereinstieg\",\n",
    "                \"anzahl_lernende\",\"anzahl_lehrvertraege\",\n",
    "                \"anzahl_lehrvertraege_lva\"]:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "    # Zeilen → Dict → Sammelliste\n",
    "    for _, r in df.iterrows():\n",
    "        rows.append({\n",
    "            # FK-IDs\n",
    "            \"abschlussniveau_id\":   fk(\"abschlussniveau\",   r.get(\"abschlussniveau\")),\n",
    "            \"lernform_id\":          fk(\"lernform\",          r.get(\"lernform\")),\n",
    "            \"geschlecht_id\":        fk(\"geschlecht\",        r.get(\"geschlecht\")),\n",
    "            \"mig_status_id\":        fk(\"mig_status\",        r.get(\"mig_status\")),\n",
    "            \"anschlussart_id\":      fk(\"lva_anschlussart\",  r.get(\"lva_anschlussart\")),\n",
    "            \"qv_status_id\":         fk(\"qv_status\",         r.get(\"qv_status\")),\n",
    "            \"lva_zeitpunkt_id\":     fk(\"lva_zeitpunkt\",     r.get(\"lva_zeitpunkt\")),\n",
    "            \"wiedereinst_dauer_id\": fk(\"wiedereinst_dauer\", r.get(\"wiedereinstieg_dauer\")),\n",
    "            \"isced_id\":             fk(\"isced\",             r.get(\"ausbildungsfeld_isced_code\")),\n",
    "            \"beruf_id\":             fk(\"beruf\",             r.get(\"beruf_bez\")),\n",
    "            # Kennzahlen\n",
    "            \"anzahl_lernende_wiedereinstieg\": r.get(\"anzahl_lernende_wiedereinstieg\"),\n",
    "            \"anzahl_lernende\":                r.get(\"anzahl_lernende\"),\n",
    "            \"anzahl_lehrvertraege_lva\":       r.get(\"anzahl_lehrvertraege_lva\"),\n",
    "            \"anzahl_lernende_lva\":            r.get(\"anzahl_lernende_lva\"),\n",
    "            # Flags & Metadaten\n",
    "            \"is_lva\":            int(pd.notna(r.get(\"anzahl_lernende_lva\"))),\n",
    "            \"is_wiedereinstieg\": int(pd.notna(r.get(\"anzahl_lernende_wiedereinstieg\"))),\n",
    "            \"datenstatus\":       r.get(\"datenstatus\"),\n",
    "            \"kohorte_id\":        1\n",
    "        })\n",
    "    print(f\"✓ {sh}: {len(df)} Zeilen gelesen\")\n",
    "\n",
    "# ── 5. DataFrame → MySQL ───────────────────────────────────────────────\n",
    "pd.DataFrame(rows).to_sql(\"fact_lva_stats\", engine,\n",
    "                          if_exists=\"append\", index=False, method=\"multi\")\n",
    "print(\"✔ fact_lva_stats geladen:\", len(rows), \"Zeilen\")\n",
    "# ----------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4c7ecbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Notebook Transformiert & lädt fact_lva_stats (Lehrvertrags­auflösungen = lva)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c5451f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Grund-Setup -------------------------------------------------\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "from pathlib import Path\n",
    "\n",
    "# Excel-Datei(en)\n",
    "sources = [Path(\"../../data/bfs_data_lva.xlsx\")]   # Pfad ggf. prüfen\n",
    "\n",
    "# DB-Verbindung\n",
    "engine = create_engine(\n",
    "    \"mysql+pymysql://root:voc_root@localhost:3306/vocdata\",\n",
    "    future=True, echo=False\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4468e85f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fact_lva_stats geleert – starte Import …\n",
      "✓ T1_Lernform_Data: 7 Zeilen\n",
      "✓ T2_Geschlecht_Data: 9 Zeilen\n",
      "✓ T3_MIG_Status_Data: 13 Zeilen\n",
      "✓ T4_ISCED_Data: 31 Zeilen\n",
      "✓ T4.1_ISCED_EBA_Data: 20 Zeilen\n",
      "✓ T4.2_ISCED_EFZ3_Data: 30 Zeilen\n",
      "✓ T4.3_ISCED_EFZ4_Data: 18 Zeilen\n",
      "✓ T4.1.1_ISCED_Beruf_EBA_Data: 55 Zeilen\n",
      "✓ T4.2.1_ISCED_Beruf_EFZ3_Data: 106 Zeilen\n",
      "✓ T4.3.1_ISCED_Beruf_EFZ4_Data: 67 Zeilen\n",
      "✓ T5_LVA_t_Data: 12 Zeilen\n",
      "✓ T6_Wiedereinstieg_Data: 6 Zeilen\n",
      "✓ T7_Zeitpkt_Wiedereinstieg_Data: 9 Zeilen\n",
      "✓ T8_Geschlecht_Wiedereinst_Data: 6 Zeilen\n",
      "✓ T9_ISCED_Beruf_WEstg_G_Data: 207 Zeilen\n",
      "✓ T9_ISCED_Beruf_WEstg_EBA_Data: 48 Zeilen\n",
      "✓ T9_ISCED_Beruf_WEstg_EFZ3_Data: 98 Zeilen\n",
      "✓ T9_ISCED_Beruf_WEstg_EFZ4_Data: 61 Zeilen\n",
      "✓ T10_Anschlussart_LVA_Data: 24 Zeilen\n",
      "✓ T11_QV_Status_Ende_t_Data: 12 Zeilen\n",
      "✓ T12_QV_Status_Ende_t_sex_Data: 24 Zeilen\n",
      "✓ T13_QV_Status_Ende_t_MIG_Data: 48 Zeilen\n",
      "✓ T14_QV_Status_Ende_t_Beruf_Data: 280 Zeilen\n",
      "✔ fact_lva_stats geladen: 1191 Zeilen\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#3. Dimensionen aus MySQL in Lookup-Dictionaries laden FK-Mapping\n",
    "# ---------------------------------------------------------------\n",
    "dim_tables = [\n",
    "    \"abschlussniveau\", \"lernform\", \"geschlecht\", \"mig_status\",\n",
    "    \"lva_anschlussart\", \"qv_status\", \"lva_zeitpunkt\",\n",
    "    \"wiedereinst_dauer\", \"isced\", \"beruf\"\n",
    "]\n",
    "\n",
    "\n",
    "lookups = {}\n",
    "with engine.begin() as con:\n",
    "    for dim in dim_tables:\n",
    "        df = pd.read_sql(f\"SELECT * FROM dim_{dim}\", con)\n",
    "        code = f\"{dim}_code\" if f\"{dim}_code\" in df.columns else f\"{dim}_bez\"\n",
    "        lookups[dim] = df[[code,f\"{dim}_id\"]].set_index(code).to_dict()[f\"{dim}_id\"]\n",
    "\n",
    "def safe(dim, key):\n",
    "    return 0 if pd.isna(key) or str(key).strip()==\"\" \\\n",
    "             else lookups[dim].get(str(key).strip().upper(),0)\n",
    "\n",
    "def map_ids(r):\n",
    "    return {\n",
    "        \"abschlussniveau_id\":   safe(\"abschlussniveau\",   r.get(\"abschlussniveau\")),\n",
    "        \"lernform_id\":          safe(\"lernform\",          r.get(\"lernform\")),\n",
    "        \"geschlecht_id\":        safe(\"geschlecht\",        r.get(\"geschlecht\")),\n",
    "        \"mig_status_id\":        safe(\"mig_status\",        r.get(\"mig_status\")),\n",
    "        \"anschlussart_id\":      safe(\"lva_anschlussart\",      r.get(\"lva_anschlussart\")),\n",
    "        \"qv_status_id\":         safe(\"qv_status\",         r.get(\"qv_status\")),\n",
    "        \"lva_zeitpunkt_id\":     safe(\"lva_zeitpunkt\",     r.get(\"lva_zeitpunkt\")),\n",
    "        \"wiedereinst_dauer_id\": safe(\"wiedereinst_dauer\", r.get(\"wiedereinstieg_dauer\")),\n",
    "        \"isced_id\":             safe(\"isced\",             r.get(\"ausbildungsfeld_isced_code\")),\n",
    "        \"beruf_id\":             safe(\"beruf\",             r.get(\"beruf_bez\")),\n",
    "    }\n",
    "\n",
    "# Tabelle leeren -----------------------------------------------------\n",
    "with engine.begin() as con:\n",
    "    con.exec_driver_sql(\"TRUNCATE TABLE fact_lva_stats;\")\n",
    "print(\"fact_lva_stats geleert – starte Import …\")\n",
    "\n",
    "# Excel → Insert-Liste ----------------------------------------------\n",
    "rows = []\n",
    "for src in sources:\n",
    "    xls = pd.ExcelFile(src)\n",
    "    for sh in [s for s in xls.sheet_names if s.endswith(\"_Data\")]:\n",
    "        head = pd.read_excel(xls, sheet_name=sh, nrows=15, header=None)\n",
    "        hdr  = next(i for i,r in head.iterrows() if r.notna().sum()>=3)\n",
    "        df   = pd.read_excel(xls, sheet_name=sh, header=hdr)\n",
    "\n",
    "        num = [\"anzahl_lernende_lva\",\"anzahl_lernende_wiedereinstieg\",\n",
    "               \"anzahl_lernende\",\"anzahl_lehrvertraege\",\n",
    "               \"anzahl_lehrvertraege_lva\"]\n",
    "        for c in num:\n",
    "            if c in df.columns: df[c]=pd.to_numeric(df[c],errors=\"coerce\")\n",
    "\n",
    "        for _,r in df.iterrows():\n",
    "            rows.append({\n",
    "                **map_ids(r),\n",
    "                \"anzahl_lernende_wiedereinstieg\": r.get(\"anzahl_lernende_wiedereinstieg\"),\n",
    "                \"anzahl_lernende\":                r.get(\"anzahl_lernende\"),\n",
    "                \"anzahl_lehrvertraege_lva\":       r.get(\"anzahl_lehrvertraege_lva\"),\n",
    "                \"anzahl_lernende_lva\":            r.get(\"anzahl_lernende_lva\"),\n",
    "                \"is_lva\":          int(pd.notna(r.get(\"anzahl_lernende_lva\"))),\n",
    "                \"is_wiedereinstieg\":int(pd.notna(r.get(\"anzahl_lernende_wiedereinstieg\"))),\n",
    "                \"datenstatus\":     r.get(\"datenstatus\"),\n",
    "                \"kohorte_id\":      1\n",
    "            })\n",
    "        print(f\"✓ {sh}: {len(df)} Zeilen\")\n",
    "\n",
    "# DataFrame → MySQL --------------------------------------------------\n",
    "pd.DataFrame(rows).to_sql(\"fact_lva_stats\", engine, if_exists=\"append\", index=False)\n",
    "print(\"✔ fact_lva_stats geladen:\", len(rows), \"Zeilen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98e20c83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dimensionen geprüft / ergänzt.\n"
     ]
    }
   ],
   "source": [
    "# ----------------- Dimensionen prüfen & ggf. auffüllen -----------------\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "engine = create_engine(\n",
    "    \"mysql+pymysql://root:voc_root@localhost:3306/vocdata\",\n",
    "    future=True, echo=False)\n",
    "\n",
    "# 1) Erwartete Minimal-IDs für jede Dimension\n",
    "DIM_EXPECTED = {\n",
    "    \"abschlussniveau\":   [(0,\"UNKNOWN\"), (1,\"EBA\"), (2,\"EFZ3\"), (3,\"EFZ4\")],\n",
    "    \"lernform\":          [(0,\"UNKNOWN\")],\n",
    "    \"geschlecht\":        [(0,\"UNKNOWN\"), (1,\"M\"), (2,\"W\")],\n",
    "    \"mig_status\":        [(0,\"UNKNOWN\")],\n",
    "    \"lva_anschlussart\":  [(0,\"UNKNOWN\")],\n",
    "    \"qv_status\":         [(0,\"UNKNOWN\")],\n",
    "    \"lva_zeitpunkt\":     [(0,\"UNKNOWN\")],\n",
    "    \"wiedereinst_dauer\": [(0,\"UNKNOWN\")],\n",
    "    \"isced\":             [(0,\"UNKNOWN\")],\n",
    "    \"beruf\":             [(0,\"UNKNOWN\")]\n",
    "}\n",
    "\n",
    "with engine.begin() as con:\n",
    "    for dim, rows in DIM_EXPECTED.items():\n",
    "        # Spaltennamen holen (wir brauchen nur ID & Code/Bez)\n",
    "        cols = pd.read_sql(f\"SHOW COLUMNS FROM dim_{dim}\", con)[\"Field\"].tolist()\n",
    "        id_col  = f\"{dim}_id\"\n",
    "        textcol = next(c for c in cols if c != id_col)\n",
    "        insert_stmt = text(                              # ← Statement als TextClause\n",
    "        f\"INSERT IGNORE INTO dim_{dim} ({id_col}, {textcol}) \"\n",
    "        \"VALUES (:id, :txt)\"\n",
    ")\n",
    "\n",
    "    for _id, _txt in rows:\n",
    "        con.execute(insert_stmt, {\"id\": int(_id), \"txt\": _txt})\n",
    "\n",
    "print(\"✅ Dimensionen geprüft / ergänzt.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "81ea6eb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fact_lva_stats geleert – Import startet …\n",
      "✓ T1_Lernform_Data: 7 Zeilen gelesen\n",
      "✓ T2_Geschlecht_Data: 9 Zeilen gelesen\n",
      "✓ T3_MIG_Status_Data: 13 Zeilen gelesen\n",
      "✓ T4_ISCED_Data: 31 Zeilen gelesen\n",
      "✓ T4.1_ISCED_EBA_Data: 20 Zeilen gelesen\n",
      "✓ T4.2_ISCED_EFZ3_Data: 30 Zeilen gelesen\n",
      "✓ T4.3_ISCED_EFZ4_Data: 18 Zeilen gelesen\n",
      "✓ T4.1.1_ISCED_Beruf_EBA_Data: 55 Zeilen gelesen\n",
      "✓ T4.2.1_ISCED_Beruf_EFZ3_Data: 106 Zeilen gelesen\n",
      "✓ T4.3.1_ISCED_Beruf_EFZ4_Data: 67 Zeilen gelesen\n",
      "✓ T5_LVA_t_Data: 12 Zeilen gelesen\n",
      "✓ T6_Wiedereinstieg_Data: 6 Zeilen gelesen\n",
      "✓ T7_Zeitpkt_Wiedereinstieg_Data: 9 Zeilen gelesen\n",
      "✓ T8_Geschlecht_Wiedereinst_Data: 6 Zeilen gelesen\n",
      "✓ T9_ISCED_Beruf_WEstg_G_Data: 207 Zeilen gelesen\n",
      "✓ T9_ISCED_Beruf_WEstg_EBA_Data: 48 Zeilen gelesen\n",
      "✓ T9_ISCED_Beruf_WEstg_EFZ3_Data: 98 Zeilen gelesen\n",
      "✓ T9_ISCED_Beruf_WEstg_EFZ4_Data: 61 Zeilen gelesen\n",
      "✓ T10_Anschlussart_LVA_Data: 24 Zeilen gelesen\n",
      "✓ T11_QV_Status_Ende_t_Data: 12 Zeilen gelesen\n",
      "✓ T12_QV_Status_Ende_t_sex_Data: 24 Zeilen gelesen\n",
      "✓ T13_QV_Status_Ende_t_MIG_Data: 48 Zeilen gelesen\n",
      "✓ T14_QV_Status_Ende_t_Beruf_Data: 280 Zeilen gelesen\n",
      "✔ fact_lva_stats geladen: 1191 Zeilen\n"
     ]
    }
   ],
   "source": [
    "# ----------------- 05_load_facts_lva — Komplett-Loader -----------------\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "# ── 1. Pfad & DB ───────────────────────────────────────────────────────\n",
    "SRC_FILE = Path(\"../../data/bfs_data_lva.xlsx\")          # relativ zum Repo\n",
    "engine    = create_engine(\"mysql+pymysql://root:voc_root@localhost:3306/vocdata\",\n",
    "                          future=True, echo=False)\n",
    "\n",
    "# ── 2. Dimension-Lookups holen  (Key = Code/Bez  ➜  Value = ID) ────────\n",
    "dim_tables = [\n",
    "    \"abschlussniveau\", \"lernform\", \"geschlecht\", \"mig_status\",\n",
    "    \"lva_anschlussart\", \"qv_status\", \"lva_zeitpunkt\",\n",
    "    \"wiedereinst_dauer\", \"isced\", \"beruf\"\n",
    "]\n",
    "\n",
    "lookups = {}\n",
    "with engine.begin() as con:\n",
    "    for dim in dim_tables:\n",
    "        df = pd.read_sql(f\"SELECT * FROM dim_{dim}\", con)\n",
    "        key = f\"{dim}_code\" if f\"{dim}_code\" in df.columns else f\"{dim}_bez\"\n",
    "        lookups[dim] = df.set_index(key)[f\"{dim}_id\"].to_dict()\n",
    "\n",
    "def fk(dim, val):\n",
    "    \"\"\"Liefert gültige FK-ID oder 0 (UNKNOWN).\"\"\"\n",
    "    return 0 if pd.isna(val) or str(val).strip()==\"\" \\\n",
    "             else lookups[dim].get(str(val).strip().upper(), 0)\n",
    "\n",
    "# ── 3. Faktentabelle leeren ────────────────────────────────────────────\n",
    "with engine.begin() as con:\n",
    "    con.exec_driver_sql(\"TRUNCATE TABLE fact_lva_stats;\")\n",
    "print(\"fact_lva_stats geleert – Import startet …\")\n",
    "\n",
    "# ── 4. Excel durchgehen & Zeilen sammeln ───────────────────────────────\n",
    "rows, xls = [], pd.ExcelFile(SRC_FILE)\n",
    "for sh in [s for s in xls.sheet_names if s.endswith(\"_Data\")]:\n",
    "    # Header suchen (erste Zeile mit ≥3 Werten)\n",
    "    header = next(i for i,r in pd.read_excel(xls, sheet_name=sh,\n",
    "                                             nrows=15, header=None\n",
    "                                             ).iterrows() if r.notna().sum()>=3)\n",
    "    df = pd.read_excel(xls, sheet_name=sh, header=header)\n",
    "\n",
    "    # numerische Spalten sicher konvertieren\n",
    "    for col in [\"anzahl_lernende_lva\",\"anzahl_lernende_wiedereinstieg\",\n",
    "                \"anzahl_lernende\",\"anzahl_lehrvertraege\",\n",
    "                \"anzahl_lehrvertraege_lva\"]:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "    # Zeilen → Dict → Sammelliste\n",
    "    for _, r in df.iterrows():\n",
    "        rows.append({\n",
    "            # FK-IDs\n",
    "            \"abschlussniveau_id\":   fk(\"abschlussniveau\",   r.get(\"abschlussniveau\")),\n",
    "            \"lernform_id\":          fk(\"lernform\",          r.get(\"lernform\")),\n",
    "            \"geschlecht_id\":        fk(\"geschlecht\",        r.get(\"geschlecht\")),\n",
    "            \"mig_status_id\":        fk(\"mig_status\",        r.get(\"mig_status\")),\n",
    "            \"anschlussart_id\":      fk(\"lva_anschlussart\",  r.get(\"lva_anschlussart\")),\n",
    "            \"qv_status_id\":         fk(\"qv_status\",         r.get(\"qv_status\")),\n",
    "            \"lva_zeitpunkt_id\":     fk(\"lva_zeitpunkt\",     r.get(\"lva_zeitpunkt\")),\n",
    "            \"wiedereinst_dauer_id\": fk(\"wiedereinst_dauer\", r.get(\"wiedereinstieg_dauer\")),\n",
    "            \"isced_id\":             fk(\"isced\",             r.get(\"ausbildungsfeld_isced_code\")),\n",
    "            \"beruf_id\":             fk(\"beruf\",             r.get(\"beruf_bez\")),\n",
    "            # Kennzahlen\n",
    "            \"anzahl_lernende_wiedereinstieg\": r.get(\"anzahl_lernende_wiedereinstieg\"),\n",
    "            \"anzahl_lernende\":                r.get(\"anzahl_lernende\"),\n",
    "            \"anzahl_lehrvertraege_lva\":       r.get(\"anzahl_lehrvertraege_lva\"),\n",
    "            \"anzahl_lernende_lva\":            r.get(\"anzahl_lernende_lva\"),\n",
    "            # Flags & Metadaten\n",
    "            \"is_lva\":            int(pd.notna(r.get(\"anzahl_lernende_lva\"))),\n",
    "            \"is_wiedereinstieg\": int(pd.notna(r.get(\"anzahl_lernende_wiedereinstieg\"))),\n",
    "            \"datenstatus\":       r.get(\"datenstatus\"),\n",
    "            \"kohorte_id\":        1\n",
    "        })\n",
    "    print(f\"✓ {sh}: {len(df)} Zeilen gelesen\")\n",
    "\n",
    "# ── 5. DataFrame → MySQL ───────────────────────────────────────────────\n",
    "pd.DataFrame(rows).to_sql(\"fact_lva_stats\", engine,\n",
    "                          if_exists=\"append\", index=False, method=\"multi\")\n",
    "print(\"✔ fact_lva_stats geladen:\", len(rows), \"Zeilen\")\n",
    "# ----------------------------------------------------------------------\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vocdata",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
